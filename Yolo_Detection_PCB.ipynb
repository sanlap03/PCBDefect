{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvXC4nJki0V4",
        "outputId": "ced88bbf-9ee6-490f-ddab-367cd7fd7499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'XmlToTxt'...\n",
            "remote: Enumerating objects: 108, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "Receiving objects: 100% (108/108), 17.58 KiB | 1.95 MiB/s, done.\n",
            "remote: Total 108 (delta 23), reused 19 (delta 17), pack-reused 76 (from 1)\u001b[K\n",
            "Resolving deltas: 100% (52/52), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/isabek/XmlToTxt.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(r\"/content/drive/MyDrive/PCB/imagedataset/XmlToTxt\")\n",
        "!python xmltotxt.py -c classes.txt -xml xml -out out"
      ],
      "metadata": {
        "id": "57oH64oGyJGn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "175de54b-3237-43da-b0a3-f1b8cac3906d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: declxml==0.9.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/XmlToTxt/requirements.txt (line 1)) (0.9.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import shutil\n",
        "import glob\n",
        "import random\n",
        "\n",
        "def collect_files(source_folder, img_ext=\".jpg\", lbl_ext=\".txt\"):\n",
        "    \"\"\"Collect and return lists of image and label file paths.\"\"\"\n",
        "    img_files=[]\n",
        "    label_files=[]\n",
        "    for root, dirs, files in os.walk(source_folder):\n",
        "        for file in files:\n",
        "            if file.endswith('.txt'):\n",
        "                label_files.append(file)\n",
        "            else:\n",
        "                img_files.append(file)\n",
        "\n",
        "    return img_files, label_files\n",
        "\n",
        "def split_dataset(image_files, train_ratio=0.8):\n",
        "    \"\"\"Shuffle and split image file paths into training and validation sets.\"\"\"\n",
        "    random.shuffle(image_files)\n",
        "    train_count = int(len(image_files) * train_ratio)\n",
        "    train_files = image_files[:train_count]\n",
        "    val_files = image_files[train_count:]\n",
        "    return train_files, val_files\n",
        "\n"
      ],
      "metadata": {
        "id": "Y5urbSTx3Zhp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path, target_size=(224, 224)):\n",
        "    \"\"\"Load, preprocess, and return an image as a numpy array.\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        return None\n",
        "    img = cv2.resize(img, target_size)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.normalize(img.astype(np.float32), None, 0, 255, cv2.NORM_MINMAX)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "    gauss_img = cv2.GaussianBlur(img, (5, 5), 0)\n",
        "    unsharp_image = cv2.addWeighted(img, 2.0, gauss_img, -1.0, 0)\n",
        "    return unsharp_image"
      ],
      "metadata": {
        "id": "EfHYzEcydOFx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_files(file_list, dest_img_dir, dest_lbl_dir, source_dir, label_ext=\".txt\"):\n",
        "    \"\"\"Save processed images and copy corresponding label files.\"\"\"\n",
        "    for img_path in file_list:\n",
        "        img_name = img_path\n",
        "        lbl_name = img_name.replace('.jpg', label_ext)\n",
        "        lbl_path = os.path.join(source_dir, lbl_name)\n",
        "        image_path= os.path.join(source_dir,img_name)\n",
        "\n",
        "        # Check if label file exists before proceeding\n",
        "        if not os.path.isfile(lbl_path):\n",
        "            print(f\"Warning: Label file {lbl_name} not found for image {img_name}. Skipping this pair.\")\n",
        "            continue\n",
        "\n",
        "        processed_img = preprocess_image(image_path)\n",
        "        if processed_img is None:\n",
        "            print(f\"Warning: Image processing failed for {img_name}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Save the processed image\n",
        "        img_save_path = os.path.join(dest_img_dir, img_name)\n",
        "        cv2.imwrite(img_save_path, processed_img)\n",
        "\n",
        "\n",
        "        # Copy the label file\n",
        "        label_save_path = os.path.join(dest_lbl_dir, lbl_name)\n",
        "        shutil.copy(lbl_path, label_save_path)\n",
        "\n",
        "\n",
        "def to_v5_directories(train_img_dir, val_img_dir, train_lbl_dir, val_lbl_dir, source_folder):\n",
        "    \"\"\"Main function to organize dataset into train and validation sets.\"\"\"\n",
        "    images, labels = collect_files(source_folder)\n",
        "\n",
        "    # Ensure we have matching images and labels\n",
        "\n",
        "    if len(images) == 0:\n",
        "        print(\"No matching image-label pairs found.\")\n",
        "        return\n",
        "\n",
        "    train_imgs, val_imgs = split_dataset(images)\n",
        "\n",
        "    # Ensure destination directories exist\n",
        "    os.makedirs(train_img_dir, exist_ok=True)\n",
        "    os.makedirs(val_img_dir, exist_ok=True)\n",
        "    os.makedirs(train_lbl_dir, exist_ok=True)\n",
        "    os.makedirs(val_lbl_dir, exist_ok=True)\n",
        "\n",
        "    # Save train and validation files\n",
        "\n",
        "    save_files(train_imgs, train_img_dir, train_lbl_dir, source_folder)\n",
        "\n",
        "    save_files(val_imgs, val_img_dir, val_lbl_dir, source_folder)\n",
        "\n",
        "    print(\"Training images:\", len(train_imgs))\n",
        "    print(\"Validation images:\", len(val_imgs))"
      ],
      "metadata": {
        "id": "QCpAyj5SdpkN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_v5_directories(\"/content/drive/MyDrive/PCB/imagedataset/dataset/images/train2\", \"/content/drive/MyDrive/PCB/imagedataset/dataset/images/val2\", \"/content/drive/MyDrive/PCB/imagedataset/dataset/labels/train2\",\"/content/drive/MyDrive/PCB/imagedataset/dataset/labels/val2\",\"/content/drive/MyDrive/PCB/imagedataset/images\")\n"
      ],
      "metadata": {
        "id": "aRE9paI5szdl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64cd993-f894-4902-f0fc-4da2711cbc90"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images: 346\n",
            "Validation images: 87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eTJclq00lrph"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}