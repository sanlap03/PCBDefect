{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvXC4nJki0V4",
        "outputId": "8042f13f-ce17-4139-cc20-b52699a92178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'XmlToTxt'...\n",
            "remote: Enumerating objects: 108, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 108 (delta 26), reused 22 (delta 20), pack-reused 73 (from 1)\u001b[K\n",
            "Receiving objects: 100% (108/108), 17.34 KiB | 8.67 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/isabek/XmlToTxt.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(r\"/content/drive/MyDrive/PCB/imagedataset/XmlToTxt\")\n",
        "!python xmltotxt.py -c classes.txt -xml xml -out out"
      ],
      "metadata": {
        "id": "O84pU6Opnw_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import shutil\n",
        "import glob\n",
        "import random\n",
        "\n",
        "def collect_files(source_folder, img_ext=\".jpg\", lbl_ext=\".txt\"):\n",
        "    \"\"\"Collect and return lists of image and label file paths.\"\"\"\n",
        "    img_files=[]\n",
        "    label_files=[]\n",
        "    for root, dirs, files in os.walk(source_folder):\n",
        "        for file in files:\n",
        "            if file.endswith('.txt'):\n",
        "                label_files.append(file)\n",
        "            else:\n",
        "                img_files.append(file)\n",
        "\n",
        "    return img_files, label_files\n",
        "\n",
        "def split_dataset(image_files,label_files, train_ratio=0.8):\n",
        "    \"\"\"Shuffle and split image file paths into training and validation sets.\"\"\"\n",
        "\n",
        "    train_count = int(len(image_files) * train_ratio)\n",
        "    train_files_images = image_files[:train_count]\n",
        "    val_files_images = image_files[train_count:]\n",
        "    train_files_labels = label_files[:train_count]\n",
        "    val_files_labels = label_files[train_count:]\n",
        "    return train_files_images, val_files_images,train_files_labels,val_files_labels\n",
        "\n"
      ],
      "metadata": {
        "id": "Y5urbSTx3Zhp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path, target_size=(224, 224)):\n",
        "    \"\"\"Load, preprocess, and return an image as a numpy array.\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        return None\n",
        "    img = cv2.resize(img, target_size)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.normalize(img.astype(np.float32), None, 0, 255, cv2.NORM_MINMAX)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "    gauss_img = cv2.GaussianBlur(img, (5, 5), 0)\n",
        "    unsharp_image = cv2.addWeighted(img, 2.0, gauss_img, -1.0, 0)\n",
        "    return unsharp_image"
      ],
      "metadata": {
        "id": "EfHYzEcydOFx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_files(images,labels, dest_img_dir, dest_lbl_dir, source_dir, label_ext=\".txt\"):\n",
        "    \"\"\"Save processed images and copy corresponding label files.\"\"\"\n",
        "    for i in range(len(images)):\n",
        "        img_name = images[i]\n",
        "        lbl_name = labels[i]\n",
        "        lbl_path = os.path.join(source_dir, lbl_name)\n",
        "        image_path= os.path.join(source_dir,img_name)\n",
        "\n",
        "        # Check if label file exists before proceeding\n",
        "        if not os.path.isfile(lbl_path):\n",
        "            print(f\"Warning: Label file {lbl_name} not found for image {img_name}. Skipping this pair.\")\n",
        "            continue\n",
        "\n",
        "        processed_img = preprocess_image(image_path)\n",
        "        if processed_img is None:\n",
        "            print(f\"Warning: Image processing failed for {img_name}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Save the processed image\n",
        "        img_save_path = os.path.join(dest_img_dir, img_name)\n",
        "        cv2.imwrite(img_save_path, processed_img)\n",
        "\n",
        "\n",
        "        # Copy the label file\n",
        "        label_save_path = os.path.join(dest_lbl_dir, lbl_name)\n",
        "        shutil.copy(lbl_path, label_save_path)\n",
        "\n",
        "\n",
        "def to_v5_directories(train_img_dir, val_img_dir, train_lbl_dir, val_lbl_dir, source_folder):\n",
        "    \"\"\"Main function to organize dataset into train and validation sets.\"\"\"\n",
        "    images, labels = collect_files(source_folder)\n",
        "\n",
        "    # Ensure we have matching images and labels\n",
        "\n",
        "    if len(images) == 0:\n",
        "        print(\"No matching image-label pairs found.\")\n",
        "        return\n",
        "\n",
        "    train_imgs, val_imgs,train_labels,val_labels = split_dataset(images,labels)\n",
        "\n",
        "    # Ensure destination directories exist\n",
        "    os.makedirs(train_img_dir, exist_ok=True)\n",
        "    os.makedirs(val_img_dir, exist_ok=True)\n",
        "    os.makedirs(train_lbl_dir, exist_ok=True)\n",
        "    os.makedirs(val_lbl_dir, exist_ok=True)\n",
        "\n",
        "    # Save train and validation files\n",
        "\n",
        "    save_files(train_imgs,train_labels, train_img_dir, train_lbl_dir, source_folder)\n",
        "\n",
        "    save_files(val_imgs,val_labels, val_img_dir, val_lbl_dir, source_folder)\n",
        "\n",
        "    print(\"Training images:\", len(train_imgs))\n",
        "    print(\"Validation images:\", len(val_imgs))"
      ],
      "metadata": {
        "id": "QCpAyj5SdpkN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_v5_directories(\"/content/drive/MyDrive/PCB/imagedataset/dataset/images/train\", \"/content/drive/MyDrive/PCB/imagedataset/dataset/images/val\", \"/content/drive/MyDrive/PCB/imagedataset/dataset/labels/train\",\"/content/drive/MyDrive/PCB/imagedataset/dataset/labels/val\",\"/content/drive/MyDrive/LicensePlate/imagedataset/images\")\n"
      ],
      "metadata": {
        "id": "aRE9paI5szdl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13dfcf3b-9a3f-41ac-a88d-8f1df9760473"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images: 346\n",
            "Validation images: 87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eTJclq00lrph"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}